{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Model Performance:\n",
      "RMSE: 37.04\n",
      "NRMSE: 4.14%\n",
      "MAPE: 2.51%\n",
      "MBE: -0.20\n",
      "R² (Correlation Coefficient): 93.54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['SVM.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# Load the larger synthetic dataset\n",
    "data = pd.read_csv('C:\\Users\\Dell\\OneDrive\\Desktop\\DGSR\\DGSR\\DGSR\\dataset\\synthetic_solar_radiation_dataset_10000.csv')\n",
    "\n",
    "# Define independent (X) and dependent (y) variables\n",
    "X = data.drop(columns=['Global_Solar_Radiation_Wh/m²'])  # Features\n",
    "y = data['Global_Solar_Radiation_Wh/m²']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data for improved model performance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "### 1. Support Vector Machine (SVM) Model\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "svm_model = SVR(kernel='rbf')  # Using RBF kernel for non-linear regression\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with SVM\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate SVM performance metrics\n",
    "rmse_svm = np.sqrt(mean_squared_error(y_test, y_pred_svm))\n",
    "nrmse_svm = rmse_svm / (y_test.max() - y_test.min())  # NRMSE as a percentage\n",
    "mape_svm = mean_absolute_percentage_error(y_test, y_pred_svm)\n",
    "mbe_svm = np.mean(y_pred_svm - y_test)  # Mean Bias Error\n",
    "r2_svm = r2_score(y_test, y_pred_svm)\n",
    "\n",
    "print(\"\\nSVM Model Performance:\")\n",
    "print(f\"RMSE: {rmse_svm:.2f}\")\n",
    "print(f\"NRMSE: {nrmse_svm * 100:.2f}%\")\n",
    "print(f\"MAPE: {mape_svm * 100:.2f}%\")\n",
    "print(f\"MBE: {mbe_svm:.2f}\")\n",
    "print(f\"R² (Correlation Coefficient): {r2_svm* 100:.2f}\")\n",
    "\n",
    "# Save the trained model (optional)\n",
    "joblib.dump(svm_model, 'SVM.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "400/400 [==============================] - 2s 2ms/step - loss: 444029.3750 - mse: 444029.3750 - val_loss: 9699.2178 - val_mse: 9699.2178\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 8594.6387 - mse: 8594.6387 - val_loss: 7492.5566 - val_mse: 7492.5566\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 6572.0332 - mse: 6572.0332 - val_loss: 5813.3369 - val_mse: 5813.3369\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 4951.9678 - mse: 4951.9678 - val_loss: 4310.3721 - val_mse: 4310.3721\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 3519.4082 - mse: 3519.4082 - val_loss: 2960.5469 - val_mse: 2960.5469\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 2348.9441 - mse: 2348.9441 - val_loss: 1902.1229 - val_mse: 1902.1229\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 1471.5581 - mse: 1471.5581 - val_loss: 1143.6327 - val_mse: 1143.6327\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 888.3925 - mse: 888.3925 - val_loss: 687.7562 - val_mse: 687.7562\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 528.0023 - mse: 528.0023 - val_loss: 419.6871 - val_mse: 419.6871\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 311.8187 - mse: 311.8187 - val_loss: 234.0322 - val_mse: 234.0322\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 184.8162 - mse: 184.8162 - val_loss: 136.3770 - val_mse: 136.3770\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 111.8700 - mse: 111.8700 - val_loss: 87.2193 - val_mse: 87.2193\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 69.9422 - mse: 69.9422 - val_loss: 54.5252 - val_mse: 54.5252\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 44.7725 - mse: 44.7725 - val_loss: 36.2415 - val_mse: 36.2415\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 30.4116 - mse: 30.4116 - val_loss: 24.3833 - val_mse: 24.3833\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 20.2744 - mse: 20.2744 - val_loss: 16.8771 - val_mse: 16.8771\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 14.4184 - mse: 14.4184 - val_loss: 11.0218 - val_mse: 11.0218\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 9.9099 - mse: 9.9099 - val_loss: 8.5344 - val_mse: 8.5344\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 7.5630 - mse: 7.5630 - val_loss: 6.4015 - val_mse: 6.4015\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 5.1794 - mse: 5.1794 - val_loss: 3.8840 - val_mse: 3.8840\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 4.0859 - mse: 4.0859 - val_loss: 2.6322 - val_mse: 2.6322\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 2.9727 - mse: 2.9727 - val_loss: 1.8873 - val_mse: 1.8873\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 2.5114 - mse: 2.5114 - val_loss: 2.5054 - val_mse: 2.5054\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.8866 - mse: 1.8866 - val_loss: 1.9537 - val_mse: 1.9537\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.6199 - mse: 1.6199 - val_loss: 0.9126 - val_mse: 0.9126\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.6924 - mse: 1.6924 - val_loss: 0.9493 - val_mse: 0.9493\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.7504 - mse: 1.7504 - val_loss: 1.5983 - val_mse: 1.5983\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.9794 - mse: 0.9794 - val_loss: 0.8685 - val_mse: 0.8685\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.5189 - mse: 1.5189 - val_loss: 1.3185 - val_mse: 1.3185\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.7729 - mse: 1.7729 - val_loss: 3.0755 - val_mse: 3.0755\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.8564 - mse: 1.8564 - val_loss: 0.6225 - val_mse: 0.6225\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.2666 - mse: 1.2666 - val_loss: 0.7003 - val_mse: 0.7003\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 2.6304 - mse: 2.6304 - val_loss: 0.7415 - val_mse: 0.7415\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 1.3845 - mse: 1.3845 - val_loss: 0.8000 - val_mse: 0.8000\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2590 - mse: 0.2590 - val_loss: 0.9142 - val_mse: 0.9142\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.6817 - mse: 1.6817 - val_loss: 2.6035 - val_mse: 2.6035\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 1.2688 - mse: 1.2688 - val_loss: 1.4744 - val_mse: 1.4744\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 1.7132 - mse: 1.7132 - val_loss: 0.2419 - val_mse: 0.2419\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.4757 - mse: 0.4757 - val_loss: 1.6165 - val_mse: 1.6165\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.3675 - mse: 1.3675 - val_loss: 0.1836 - val_mse: 0.1836\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 2.5447 - mse: 2.5447 - val_loss: 0.3024 - val_mse: 0.3024\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7565 - mse: 0.7565 - val_loss: 4.7509 - val_mse: 4.7509\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 2.4306 - mse: 2.4306 - val_loss: 0.1682 - val_mse: 0.1682\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3568 - mse: 0.3568 - val_loss: 0.7521 - val_mse: 0.7521\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.8459 - mse: 0.8459 - val_loss: 0.4874 - val_mse: 0.4874\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 7.5711 - mse: 7.5711 - val_loss: 0.3598 - val_mse: 0.3598\n",
      "Epoch 47/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.1148 - mse: 0.1148 - val_loss: 0.0557 - val_mse: 0.0557\n",
      "Epoch 48/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.0565 - mse: 0.0565 - val_loss: 0.1280 - val_mse: 0.1280\n",
      "Epoch 49/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7121 - mse: 0.7121 - val_loss: 1.4900 - val_mse: 1.4900\n",
      "Epoch 50/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.5610 - mse: 0.5610 - val_loss: 1.5396 - val_mse: 1.5396\n",
      "63/63 [==============================] - 0s 889us/step\n",
      "Model Evaluation Metrics:\n",
      "RMSE: 1.23\n",
      "NRMSE (%): 0.14\n",
      "MAPE (%): 0.1\n",
      "MBE: -0.07\n",
      "R² (%): 99.99\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "data = pd.read_csv('C:/Users/Dell/OneDrive/Desktop/DGSR/DGSR/DGSR/dataset/synthetic_solar_radiation_dataset_10000.csv')  # Update with actual path\n",
    "X = data.drop(columns=['Global_Solar_Radiation_Wh/m²'])\n",
    "y = data['Global_Solar_Radiation_Wh/m²']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Save the scaler for later use\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Build and train the ANN model\n",
    "ann_model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "ann_model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "ann_model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_ann = ann_model.predict(X_test).flatten()\n",
    "rmse_ann = np.sqrt(mean_squared_error(y_test, y_pred_ann))\n",
    "nrmse_ann = rmse_ann / (y_test.max() - y_test.min())\n",
    "mape_ann = mean_absolute_percentage_error(y_test, y_pred_ann)\n",
    "mbe_ann = np.mean(y_pred_ann - y_test)\n",
    "r2_ann = r2_score(y_test, y_pred_ann)\n",
    "\n",
    "# Display results\n",
    "results = {\n",
    "    \"RMSE\": round(rmse_ann, 2),\n",
    "    \"NRMSE (%)\": round(nrmse_ann * 100, 2),\n",
    "    \"MAPE (%)\": round(mape_ann * 100, 2),\n",
    "    \"MBE\": round(mbe_ann, 2),\n",
    "    \"R² (%)\": round(r2_ann * 100, 2),\n",
    "}\n",
    "\n",
    "# Print each metric\n",
    "print(\"Model Evaluation Metrics:\")\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KULSUM\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model for later use\n",
    "ann_model.save('ANN_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "# Load the trained ANN model\n",
    "ann_model = tf.keras.models.load_model('ANN_model2.h5')\n",
    "\n",
    "# Load the scaler\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Dell/OneDrive/Desktop/DGSR/DGSR/DGSR/dataset/synthetic_solar_radiation_dataset_10000.csv')  \n",
    "\n",
    "# Prepare the dataset\n",
    "X = data.drop(columns=['Global_Solar_Radiation_Wh/m²'])\n",
    "y = data['Global_Solar_Radiation_Wh/m²']\n",
    "\n",
    "# Transform features using the saved scaler\n",
    "X_test = scaler.transform(X)  \n",
    "\n",
    "# Use the ANN model to predict\n",
    "y_pred_ann = ann_model.predict(X_test).flatten()\n",
    "\n",
    "# Compute performance metrics\n",
    "rmse_ann = np.sqrt(mean_squared_error(y, y_pred_ann))\n",
    "nrmse_ann = rmse_ann / (y.max() - y.min())\n",
    "mape_ann = mean_absolute_percentage_error(y, y_pred_ann)\n",
    "mbe_ann = np.mean(y_pred_ann - y)\n",
    "r2_ann = r2_score(y, y_pred_ann)\n",
    "\n",
    "# Display results\n",
    "results = {\n",
    "    \"RMSE\": round(rmse_ann, 2),\n",
    "    \"NRMSE (%)\": round(nrmse_ann * 100, 2),\n",
    "    \"MAPE (%)\": round(mape_ann * 100, 2),\n",
    "    \"MBE\": round(mbe_ann, 2),\n",
    "    \"R² (%)\": round(r2_ann * 100, 2),\n",
    "}\n",
    "\n",
    "print(\"Model Evaluation Metrics:\")\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
